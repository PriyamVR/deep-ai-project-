‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡¶ú‡ßá‡¶ï‡ßç‡¶ü‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶™‡ßÅ‡¶∞‡ßã ‡¶ó‡¶æ‡¶á‡¶°‡¶≤‡¶æ‡¶á‡¶® ‡¶ß‡¶æ‡¶™‡ßá ‡¶ß‡¶æ‡¶™‡ßá ‡¶®‡¶ø‡¶ö‡ßá ‡¶¶‡ßá‡¶ì‡ßü‡¶æ ‡¶π‡¶≤‡ßã‡•§ ‡¶è‡¶ü‡¶ø Google Colab-‡¶è **YOLOv3** ‡¶¶‡¶ø‡ßü‡ßá **Weapon Detection**, **Motion Detection**, ‡¶è‡¶¨‡¶Ç **Twilio Call Alert** ‡¶ö‡¶æ‡¶≤‡¶æ‡¶®‡ßã‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶â‡¶™‡¶Ø‡ßã‡¶ó‡ßÄ ‡¶ï‡¶∞‡ßá ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶æ ‡¶π‡ßü‡ßá‡¶õ‡ßá‡•§

---

## **‡¶ß‡¶æ‡¶™ ‡ßß: ‡¶™‡ßç‡¶∞‡¶ú‡ßá‡¶ï‡ßç‡¶ü‡ßá‡¶∞ ‡¶™‡ßç‡¶∞‡ßü‡ßã‡¶ú‡¶®‡ßÄ‡ßü ‡¶´‡¶æ‡¶á‡¶≤ ‡¶∏‡¶Ç‡¶ó‡ßç‡¶∞‡¶π ‡¶è‡¶¨‡¶Ç ‡¶™‡ßç‡¶∞‡¶∏‡ßç‡¶§‡ßÅ‡¶§‡¶ø**

‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡¶ú‡ßá‡¶ï‡ßç‡¶ü‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶™‡ßç‡¶∞‡ßü‡ßã‡¶ú‡¶®‡ßÄ‡ßü ‡¶´‡¶æ‡¶á‡¶≤‡¶ó‡ßÅ‡¶≤‡ßã:
1. **YOLOv3 Configuration Files:**
   - `yolov3_custom_train.cfg`
   - `yolov3_custom_train_final.weights`
   - `yolo.names`
2. **Python ‡¶ï‡ßã‡¶° ‡¶´‡¶æ‡¶á‡¶≤:**
   - `motion_detection.py` (‡¶Æ‡ßã‡¶∂‡¶® ‡¶°‡¶ø‡¶ü‡ßá‡¶ï‡¶∂‡¶® ‡¶≤‡¶ú‡¶ø‡¶ï‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø)
   - `yolo_detection.py` (YOLO ‡¶Æ‡¶°‡ßá‡¶≤‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø)
   - `twilio_call.py` (Twilio ‡¶ï‡¶≤‡¶ø‡¶Ç ‡¶´‡¶æ‡¶Ç‡¶∂‡¶®‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø)
3. **‡¶°‡ßá‡¶ü‡¶æ‡¶∏‡ßá‡¶ü:**
   - ‡¶õ‡¶¨‡¶ø ‡¶è‡¶¨‡¶Ç ‡¶≤‡ßá‡¶¨‡ßá‡¶≤ ‡¶´‡¶æ‡¶á‡¶≤ (‡¶á‡¶Æ‡ßá‡¶ú ‡¶´‡¶æ‡¶á‡¶≤ ‡¶è‡¶¨‡¶Ç `.txt` ‡¶≤‡ßá‡¶¨‡ßá‡¶≤ ‡¶´‡¶æ‡¶á‡¶≤)‡•§

---

## **‡¶ß‡¶æ‡¶™ ‡ß®: Google Colab-‡¶è ‡¶™‡ßç‡¶∞‡¶ú‡ßá‡¶ï‡ßç‡¶ü ‡¶´‡¶æ‡¶á‡¶≤ ‡¶Ü‡¶™‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡¶æ**

### **2.1: ‡¶™‡ßç‡¶∞‡¶ú‡ßá‡¶ï‡ßç‡¶ü ‡¶´‡¶æ‡¶á‡¶≤ ‡¶Ü‡¶™‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßÅ‡¶®**
‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡¶ú‡ßá‡¶ï‡ßç‡¶ü ‡¶´‡¶æ‡¶á‡¶≤‡¶ó‡ßÅ‡¶≤‡ßã ‡¶è‡¶ï‡¶ü‡¶ø `.zip` ‡¶´‡¶æ‡¶á‡¶≤ ‡¶π‡¶ø‡¶∏‡ßá‡¶¨‡ßá ‡¶∏‡¶Ç‡¶∞‡¶ï‡ßç‡¶∑‡¶£ ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶è‡¶¨‡¶Ç Colab-‡¶è ‡¶Ü‡¶™‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßÅ‡¶®:
```python
from google.colab import files
uploaded = files.upload()  # .zip ‡¶´‡¶æ‡¶á‡¶≤‡¶ü‡¶ø ‡¶Ü‡¶™‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßÅ‡¶®
```

### **2.2: `.zip` ‡¶´‡¶æ‡¶á‡¶≤ ‡¶Ü‡¶®‡¶ú‡¶ø‡¶™ ‡¶ï‡¶∞‡ßÅ‡¶®**
```bash
!unzip your_project.zip -d /content/project
```

---

## **‡¶ß‡¶æ‡¶™ ‡ß©: ‡¶™‡ßç‡¶∞‡¶Ø‡¶º‡ßã‡¶ú‡¶®‡ßÄ‡¶Ø‡¶º ‡¶≤‡¶æ‡¶á‡¶¨‡ßç‡¶∞‡ßá‡¶∞‡¶ø ‡¶á‡¶®‡¶∏‡ßç‡¶ü‡¶≤ ‡¶ï‡¶∞‡¶æ**

Google Colab-‡¶è ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡¶ú‡ßá‡¶ï‡ßç‡¶ü‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶™‡ßç‡¶∞‡¶Ø‡¶º‡ßã‡¶ú‡¶®‡ßÄ‡¶Ø‡¶º ‡¶∏‡¶Æ‡¶∏‡ßç‡¶§ ‡¶≤‡¶æ‡¶á‡¶¨‡ßç‡¶∞‡ßá‡¶∞‡¶ø ‡¶á‡¶®‡¶∏‡ßç‡¶ü‡¶≤ ‡¶ï‡¶∞‡ßÅ‡¶®:
```python
!pip install opencv-python-headless numpy twilio
```

---

## **‡¶ß‡¶æ‡¶™ ‡ß™: YOLOv3 ‡¶∏‡ßá‡¶ü‡¶Ü‡¶™ ‡¶ï‡¶∞‡¶æ**

### **4.1: Darknet ‡¶á‡¶®‡¶∏‡ßç‡¶ü‡¶≤ ‡¶ï‡¶∞‡ßÅ‡¶®**
YOLOv3 Darknet ‡¶´‡ßç‡¶∞‡ßá‡¶Æ‡¶ì‡ßü‡¶æ‡¶∞‡ßç‡¶ï ‡¶á‡¶®‡ßç‡¶∏‡¶ü‡¶≤ ‡¶ï‡¶∞‡ßÅ‡¶®:
```bash
!git clone https://github.com/AlexeyAB/darknet.git
%cd darknet
!make
```

### **4.2: ‡¶™‡ßç‡¶∞‡¶Ø‡¶º‡ßã‡¶ú‡¶®‡ßÄ‡¶Ø‡¶º ‡¶´‡ßã‡¶≤‡ßç‡¶°‡¶æ‡¶∞ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®**
```bash
!mkdir -p data/obj
!mkdir backup
```

### **4.3: `.data` ‡¶è‡¶¨‡¶Ç `.names` ‡¶´‡¶æ‡¶á‡¶≤ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®**
```bash
# .data ‡¶´‡¶æ‡¶á‡¶≤ ‡¶§‡ßà‡¶∞‡¶ø
!echo "classes= 1" > data/obj.data
!echo "train  = data/train.txt" >> data/obj.data
!echo "valid  = data/test.txt" >> data/obj.data
!echo "names = data/obj.names" >> data/obj.data
!echo "backup = backup/" >> data/obj.data

# .names ‡¶´‡¶æ‡¶á‡¶≤ ‡¶§‡ßà‡¶∞‡¶ø
!echo "weapon" > data/obj.names
```

---

## **‡¶ß‡¶æ‡¶™ ‡ß´: YOLOv3 ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶ü‡ßç‡¶∞‡ßá‡¶® ‡¶¨‡¶æ ‡¶á‡¶®‡¶´‡¶æ‡¶∞‡ßá‡¶®‡ßç‡¶∏ (‡¶°‡¶ø‡¶ü‡ßá‡¶ï‡¶∂‡¶®)**

### **5.1: YOLOv3 ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç ‡¶°‡ßá‡¶ü‡¶æ ‡¶™‡ßç‡¶∞‡¶∏‡ßç‡¶§‡ßÅ‡¶§ ‡¶ï‡¶∞‡ßÅ‡¶®**
‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶á‡¶Æ‡ßá‡¶ú ‡¶è‡¶¨‡¶Ç ‡¶≤‡ßá‡¶¨‡ßá‡¶≤ ‡¶´‡¶æ‡¶á‡¶≤ `data/obj` ‡¶´‡ßã‡¶≤‡ßç‡¶°‡¶æ‡¶∞‡ßá ‡¶Ü‡¶™‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßÅ‡¶®‡•§ ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç ‡¶°‡ßá‡¶ü‡¶æ‡¶∞ ‡¶™‡¶æ‡¶• ‡¶≤‡¶ø‡¶∏‡ßç‡¶ü ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®:
```bash
!find $(pwd)/data/obj -name "*.jpg" > data/train.txt
```

### **5.2: YOLOv3 ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶°‡¶ø‡¶ü‡ßá‡¶ï‡¶∂‡¶® ‡¶ö‡¶æ‡¶≤‡¶æ‡¶®**
Python ‡¶ï‡ßã‡¶° ‡¶¶‡¶ø‡ßü‡ßá YOLOv3 ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶ö‡¶æ‡¶≤‡¶æ‡¶®:
```python
import cv2
import numpy as np

# Load YOLO model
net = cv2.dnn.readNet("yolov3_custom_train_final.weights", "yolov3_custom_train.cfg")
classes = []
with open("yolo.names", "r") as f:
    classes = [line.strip() for line in f.readlines()]

# Load image
image = cv2.imread("/content/project/test_image.jpg")
height, width, _ = image.shape

# Prepare input blob
blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)
net.setInput(blob)

# Run inference
layer_names = net.getLayerNames()
output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]
outs = net.forward(output_layers)

# Process detections
class_ids = []
confidences = []
boxes = []
for out in outs:
    for detection in out:
        scores = detection[5:]
        class_id = np.argmax(scores)
        confidence = scores[class_id]
        if confidence > 0.5:
            center_x, center_y, w, h = (
                int(detection[0] * width),
                int(detection[1] * height),
                int(detection[2] * width),
                int(detection[3] * height),
            )
            x = int(center_x - w / 2)
            y = int(center_y - h / 2)
            boxes.append([x, y, w, h])
            confidences.append(float(confidence))
            class_ids.append(class_id)

# Draw bounding boxes
for i in range(len(boxes)):
    x, y, w, h = boxes[i]
    label = str(classes[class_ids[i]])
    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)
    cv2.putText(image, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

# Display image
from google.colab.patches import cv2_imshow
cv2_imshow(image)
```

---

## **‡¶ß‡¶æ‡¶™ ‡ß¨: ‡¶Æ‡ßã‡¶∂‡¶® ‡¶°‡¶ø‡¶ü‡ßá‡¶ï‡¶∂‡¶® ‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§ ‡¶ï‡¶∞‡¶æ**

Python ‡¶∏‡ßç‡¶ï‡ßç‡¶∞‡¶ø‡¶™‡ßç‡¶ü‡ßá‡¶∞ ‡¶Æ‡¶æ‡¶ß‡ßç‡¶Ø‡¶Æ‡ßá **‡¶Æ‡ßã‡¶∂‡¶® ‡¶°‡¶ø‡¶ü‡ßá‡¶ï‡¶∂‡¶®** ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®:
```python
# Initialize camera
cap = cv2.VideoCapture(0)
ret, frame1 = cap.read()
ret, frame2 = cap.read()

while True:
    diff = cv2.absdiff(frame1, frame2)
    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)
    blur = cv2.GaussianBlur(gray, (5, 5), 0)
    _, thresh = cv2.threshold(blur, 20, 255, cv2.THRESH_BINARY)
    dilated = cv2.dilate(thresh, None, iterations=3)
    contours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

    for contour in contours:
        if cv2.contourArea(contour) < 5000:
            continue
        x, y, w, h = cv2.boundingRect(contour)
        cv2.rectangle(frame1, (x, y), (x + w, y + h), (0, 255, 0), 2)

    cv2.imshow("feed", frame1)
    frame1 = frame2
    ret, frame2 = cap.read()

    if cv2.waitKey(10) == 27:
        break

cap.release()
cv2.destroyAllWindows()
```

---

## **‡¶ß‡¶æ‡¶™ ‡ß≠: Twilio Call Alert ‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§ ‡¶ï‡¶∞‡¶æ**

Twilio ‡¶ï‡¶≤ ‡¶´‡¶æ‡¶Ç‡¶∂‡¶®‡¶ü‡¶ø ‡¶®‡¶ø‡¶Æ‡ßç‡¶®‡¶∞‡ßÇ‡¶™ ‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§ ‡¶ï‡¶∞‡ßÅ‡¶®:
```python
from twilio.rest import Client

# Twilio credentials
account_sid = "your_account_sid"
auth_token = "your_auth_token"

def make_call():
    client = Client(account_sid, auth_token)
    call = client.calls.create(
        url='http://demo.twilio.com/docs/voice.xml',
        to='+919876543456',  # ‡¶≠‡ßá‡¶∞‡¶ø‡¶´‡¶æ‡ßü‡ßá‡¶° ‡¶®‡¶Æ‡ßç‡¶¨‡¶∞
        from_='+19548803109'  # Twilio Virtual Number
    )
    print("Call initiated:", call.sid)

# Call this function when motion or weapon is detected
make_call()
```

---

## **‡¶ß‡¶æ‡¶™ ‡ßÆ: ‡¶ö‡ßÇ‡ßú‡¶æ‡¶®‡ßç‡¶§ ‡¶∏‡¶Ç‡¶Æ‡¶ø‡¶∂‡ßç‡¶∞‡¶£**

1. **‡¶Æ‡ßã‡¶∂‡¶® ‡¶°‡¶ø‡¶ü‡ßá‡¶ï‡¶∂‡¶®** ‡¶ö‡¶æ‡¶≤‡¶æ‡¶®‡ßã‡¶∞ ‡¶∏‡¶Æ‡ßü ‡¶ï‡ßã‡¶®‡ßã ‡¶Æ‡ßã‡¶∂‡¶® ‡¶°‡¶ø‡¶ü‡ßá‡¶ï‡ßç‡¶ü ‡¶π‡¶≤‡ßá YOLOv3 ‡¶ö‡¶æ‡¶≤‡¶æ‡¶®‡•§
2. **Twilio Call Alert** ‡¶ö‡¶æ‡¶≤‡¶æ‡¶® ‡¶Ø‡¶ñ‡¶® ‡¶ï‡ßã‡¶®‡ßã ‡¶Ö‡¶∏‡ßç‡¶§‡ßç‡¶∞ ‡¶∂‡¶®‡¶æ‡¶ï‡ßç‡¶§ ‡¶π‡ßü‡•§

---

### ‡¶Ø‡¶¶‡¶ø ‡¶ï‡ßã‡¶®‡ßã ‡¶ß‡¶æ‡¶™ ‡¶¨‡¶æ ‡¶´‡¶æ‡¶Ç‡¶∂‡¶®‡ßá ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶π‡ßü, ‡¶ú‡¶æ‡¶®‡¶æ‡¶§‡ßá ‡¶¶‡ßç‡¶¨‡¶ø‡¶ß‡¶æ ‡¶ï‡¶∞‡¶¨‡ßá‡¶® ‡¶®‡¶æ‡•§ üòä